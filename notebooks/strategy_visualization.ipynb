{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b85623e-d921-4c39-bb4b-b7cf916b2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Add the parent directory to the path\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Import modules from our package\n",
    "from src.utils.data_utils import download_stock_data, get_current_date\n",
    "from src.strategies.momentum_trading_strategy import momentum_trading_strategy, compute_returns\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7794635-acea-408e-a5d6-eb0d2b419096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSL workaround for Yahoo Finance\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a3323fb-226f-4fad-a6ed-1ff6a80342a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing output directory: ../output\n",
      "\n",
      "Found 4 CSV files:\n",
      "  - nvda_trading_strategy_20_100.csv\n",
      "  - nvda_trading_strategy_50_200.csv\n",
      "  - NVDA_trading_strategy_5_20.csv\n",
      "  - nvda_trading_strategy_10_50.csv\n",
      "\n",
      "Found 13 image files:\n",
      "  - cumulative_returns_50_200.png\n",
      "  - nvda_trading_strategy_10_50.png\n",
      "  - cumulative_returns_20_100.png\n",
      "  - cumulative_returns_10_50.png\n",
      "  - buy_sell_signals_5_20.png\n",
      "  ... and 8 more\n"
     ]
    }
   ],
   "source": [
    "# Define the output directory\n",
    "output_dir = \"../output\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created output directory: {output_dir}\")\n",
    "else:\n",
    "    print(f\"Using existing output directory: {output_dir}\")\n",
    "    \n",
    "# List files in the output directory\n",
    "files = os.listdir(output_dir)\n",
    "csv_files = [f for f in files if f.endswith('.csv')]\n",
    "image_files = [f for f in files if f.endswith('.png')]\n",
    "\n",
    "print(f\"\\nFound {len(csv_files)} CSV files:\")\n",
    "for file in csv_files:\n",
    "    print(f\"  - {file}\")\n",
    "    \n",
    "print(f\"\\nFound {len(image_files)} image files:\")\n",
    "for file in image_files[:5]:  # Show only first 5 to avoid cluttering\n",
    "    print(f\"  - {file}\")\n",
    "if len(image_files) > 5:\n",
    "    print(f\"  ... and {len(image_files) - 5} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86d2da1a-8219-46c1-a409-c431f5651779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading nvda_trading_strategy_5_20.csv: 'Date'\n",
      "Error loading nvda_trading_strategy_10_50.csv: 'Date'\n",
      "Error loading nvda_trading_strategy_20_100.csv: 'Date'\n",
      "Error loading nvda_trading_strategy_50_200.csv: 'Date'\n"
     ]
    }
   ],
   "source": [
    "# Define the MA pairs we want to analyze\n",
    "ma_pairs = [(5, 20), (10, 50), (20, 100), (50, 200)]\n",
    "symbol = \"NVDA\"\n",
    "\n",
    "# Storage for results\n",
    "result_dfs = {}\n",
    "\n",
    "# Try to load existing result files\n",
    "for short, long in ma_pairs:\n",
    "    filename = f\"{symbol.lower()}_trading_strategy_{short}_{long}.csv\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        # Load the CSV file\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df.set_index('Date', inplace=True)\n",
    "            result_dfs[(short, long)] = df\n",
    "            print(f\"Loaded existing results for MA pair ({short}, {long})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filename}: {e}\")\n",
    "    else:\n",
    "        print(f\"No existing results found for MA pair ({short}, {long})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b582655f-734c-4fc7-bfaf-c359afff9e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['NVDA']: SSLError(MaxRetryError(\"HTTPSConnectionPool(host='fc.yahoo.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)')))\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to generate data for 4 MA pairs\n",
      "YF.download() has changed argument auto_adjust default to True\n",
      "Error downloading data: No module named 'pandas_datareader'\n",
      "Creating dummy data for testing purposes...\n",
      "Created dummy data for NVDA with 302 trading days\n",
      "Downloaded 302 days of data for NVDA\n",
      "Generating data for MA pair (5, 20)...\n",
      "Data for MA pair (5, 20) saved to nvda_trading_strategy_5_20.csv\n",
      "Generating data for MA pair (10, 50)...\n",
      "Data for MA pair (10, 50) saved to nvda_trading_strategy_10_50.csv\n",
      "Generating data for MA pair (20, 100)...\n",
      "Data for MA pair (20, 100) saved to nvda_trading_strategy_20_100.csv\n",
      "Generating data for MA pair (50, 200)...\n",
      "Data for MA pair (50, 200) saved to nvda_trading_strategy_50_200.csv\n"
     ]
    }
   ],
   "source": [
    "# Check if we need to download data\n",
    "missing_pairs = [pair for pair in ma_pairs if pair not in result_dfs]\n",
    "\n",
    "if missing_pairs:\n",
    "    print(f\"Need to generate data for {len(missing_pairs)} MA pairs\")\n",
    "    \n",
    "    # Download data\n",
    "    start_date = \"2024-01-01\"\n",
    "    end_date = get_current_date()\n",
    "    \n",
    "    try:\n",
    "        # Download data\n",
    "        df = download_stock_data(symbol, start_date, end_date)\n",
    "        print(f\"Downloaded {len(df)} days of data for {symbol}\")\n",
    "        \n",
    "        # Generate data for missing pairs\n",
    "        for short, long in missing_pairs:\n",
    "            print(f\"Generating data for MA pair ({short}, {long})...\")\n",
    "            \n",
    "            # Calculate signals\n",
    "            signals = momentum_trading_strategy(df.copy(), short, long)\n",
    "            \n",
    "            # Save to CSV\n",
    "            filename = f\"{symbol.lower()}_trading_strategy_{short}_{long}.csv\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            signals.to_csv(filepath)\n",
    "            \n",
    "            # Store in our dictionary\n",
    "            result_dfs[(short, long)] = signals\n",
    "            \n",
    "            print(f\"Data for MA pair ({short}, {long}) saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading or processing data: {e}\")\n",
    "        print(\"Creating dummy data for testing instead\")\n",
    "        \n",
    "        # Create dummy data\n",
    "        dates = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "        price = 100.0\n",
    "        prices = []\n",
    "        for _ in range(len(dates)):\n",
    "            change_percent = np.random.normal(0, 0.02)\n",
    "            price *= (1 + change_percent)\n",
    "            prices.append(price)\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'Open': prices,\n",
    "            'High': [p * (1 + abs(np.random.normal(0, 0.005))) for p in prices],\n",
    "            'Low': [p * (1 - abs(np.random.normal(0, 0.005))) for p in prices],\n",
    "            'Close': [p * (1 + np.random.normal(0, 0.002)) for p in prices],\n",
    "            'Adj Close': [p * (1 + np.random.normal(0, 0.002)) for p in prices],\n",
    "            'Volume': [int(np.random.normal(1000000, 200000)) for _ in prices]\n",
    "        }, index=dates)\n",
    "        \n",
    "        # Generate data for missing pairs\n",
    "        for short, long in missing_pairs:\n",
    "            print(f\"Generating dummy data for MA pair ({short}, {long})...\")\n",
    "            \n",
    "            # Calculate signals\n",
    "            signals = momentum_trading_strategy(df.copy(), short, long)\n",
    "            \n",
    "            # Save to CSV\n",
    "            filename = f\"{symbol.lower()}_trading_strategy_{short}_{long}.csv\"\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            signals.to_csv(filepath)\n",
    "            \n",
    "            # Store in our dictionary\n",
    "            result_dfs[(short, long)] = signals\n",
    "            \n",
    "            print(f\"Dummy data for MA pair ({short}, {long}) saved to {filename}\")\n",
    "else:\n",
    "    print(\"Already have data for all MA pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17dc9697-ef3d-4522-8bb1-caf8e5a20781",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of names must match number of levels in MultiIndex.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Create a DataFrame with performance metrics\u001b[39;00m\n\u001b[1;32m     59\u001b[0m performance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(performance)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m---> 60\u001b[0m \u001b[43mperformance_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMA Pair\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     61\u001b[0m performance_df\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     62\u001b[0m performance_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshort_window\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m performance_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMA Pair\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/autogen/lib/python3.10/site-packages/pandas/core/indexes/multi.py:1609\u001b[0m, in \u001b[0;36mMultiIndex._set_names\u001b[0;34m(self, names, level, validate)\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of names must match length of level.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels:\n\u001b[0;32m-> 1609\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1610\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of names must match number of levels in MultiIndex.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1611\u001b[0m         )\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1614\u001b[0m     level \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels)\n",
      "\u001b[0;31mValueError\u001b[0m: Length of names must match number of levels in MultiIndex."
     ]
    }
   ],
   "source": [
    "# Calculate returns and metrics for each pair\n",
    "performance = {}\n",
    "\n",
    "for pair, df in result_dfs.items():\n",
    "    # Make sure we have all required columns\n",
    "    required_columns = ['price', 'short_mavg', 'long_mavg', 'signal', 'positions']\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        # The CSV may have slightly different column names, try to adapt\n",
    "        if 'Close' in df.columns and 'price' not in df.columns:\n",
    "            df['price'] = df['Close']\n",
    "        if 'Short_MA' in df.columns and 'short_mavg' not in df.columns:\n",
    "            df['short_mavg'] = df['Short_MA']\n",
    "        if 'Long_MA' in df.columns and 'long_mavg' not in df.columns:\n",
    "            df['long_mavg'] = df['Long_MA']\n",
    "        if 'Signal' in df.columns and 'signal' not in df.columns:\n",
    "            df['signal'] = df['Signal']\n",
    "        if 'Position' in df.columns and 'positions' not in df.columns:\n",
    "            df['positions'] = df['Position']\n",
    "            \n",
    "    # Calculate daily returns if not already present\n",
    "    if 'daily_returns' not in df.columns:\n",
    "        df['daily_returns'] = df['price'].pct_change().fillna(0)\n",
    "    \n",
    "    # Calculate strategy returns if not already present\n",
    "    if 'strategy_returns' not in df.columns:\n",
    "        df['strategy_returns'] = df['signal'].shift(1).fillna(0) * df['daily_returns']\n",
    "    \n",
    "    # Calculate cumulative returns if not already present\n",
    "    if 'cumulative_strategy_return' not in df.columns:\n",
    "        df['cumulative_strategy_return'] = (1 + df['strategy_returns']).cumprod()\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    final_return = df['cumulative_strategy_return'].iloc[-1] - 1 if len(df) > 0 else 0\n",
    "    buy_signals = len(df[df['positions'] == 1.0])\n",
    "    sell_signals = len(df[df['positions'] == -1.0])\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    annual_factor = 252  # Trading days in a year\n",
    "    daily_returns = df['strategy_returns'].fillna(0)\n",
    "    volatility = daily_returns.std() * np.sqrt(annual_factor) if len(daily_returns) > 0 else 0\n",
    "    sharpe = daily_returns.mean() / daily_returns.std() * np.sqrt(annual_factor) if (len(daily_returns) > 0 and daily_returns.std() > 0) else 0\n",
    "    max_drawdown = ((1 + daily_returns).cumprod() / (1 + daily_returns).cumprod().cummax() - 1).min() if len(daily_returns) > 0 else 0\n",
    "    \n",
    "    # Store metrics\n",
    "    performance[pair] = {\n",
    "        'final_return': final_return,\n",
    "        'volatility': volatility,\n",
    "        'sharpe_ratio': sharpe,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'buy_signals': buy_signals,\n",
    "        'sell_signals': sell_signals,\n",
    "        'pair': pair\n",
    "    }\n",
    "    \n",
    "    # Update the dataframe\n",
    "    result_dfs[pair] = df\n",
    "\n",
    "# Create a DataFrame with performance metrics\n",
    "performance_df = pd.DataFrame(performance).T\n",
    "performance_df.index.names = ['MA Pair']\n",
    "performance_df.reset_index(inplace=True)\n",
    "performance_df['short_window'] = performance_df['MA Pair'].apply(lambda x: x[0])\n",
    "performance_df['long_window'] = performance_df['MA Pair'].apply(lambda x: x[1])\n",
    "\n",
    "# Sort by final return\n",
    "performance_df.sort_values('final_return', ascending=False, inplace=True)\n",
    "\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d0c2d-05e3-411e-a986-b8fed52a49fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display formatted performance metrics\n",
    "pd.set_option('display.float_format', '{:.2%}'.format)\n",
    "display_df = performance_df[['short_window', 'long_window', 'final_return', 'volatility', 'sharpe_ratio', 'max_drawdown', 'buy_signals', 'sell_signals']]\n",
    "display_df.columns = ['Short Window', 'Long Window', 'Return', 'Volatility', 'Sharpe Ratio', 'Max Drawdown', 'Buy Signals', 'Sell Signals']\n",
    "pd.set_option('display.float_format', '{:.2%}'.format)\n",
    "display_df.set_index(['Short Window', 'Long Window'], inplace=True)\n",
    "display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71e577-9469-4233-9319-804527f906eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset float format for non-percentage values\n",
    "pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e158d-66ca-444c-adff-bf33a31b86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a markdown table for the report\n",
    "markdown = \"# Momentum Trading Strategy Performance Comparison\\n\\n\"\n",
    "markdown += f\"## Stock: {symbol}\\n\\n\"\n",
    "markdown += \"| MA Pair | Return | Volatility | Sharpe | Max Drawdown | Buy Signals | Sell Signals |\\n\"\n",
    "markdown += \"|---------|--------|------------|--------|--------------|-------------|-------------|\\n\"\n",
    "\n",
    "for idx, row in performance_df.iterrows():\n",
    "    pair = row['MA Pair']\n",
    "    markdown += f\"| ({pair[0]}, {pair[1]}) | {row['final_return']:.2%} | {row['volatility']:.2%} | {row['sharpe_ratio']:.2f} | {row['max_drawdown']:.2%} | {row['buy_signals']} | {row['sell_signals']} |\\n\"\n",
    "\n",
    "# Save markdown to file\n",
    "with open(os.path.join(output_dir, \"performance_comparison.md\"), \"w\") as f:\n",
    "    f.write(markdown)\n",
    "\n",
    "print(\"Performance comparison saved to\", os.path.join(output_dir, \"performance_comparison.md\"))\n",
    "print(\"\\nMarkdown Preview:\")\n",
    "print(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3b0a15-2044-4244-9d37-8f4ff6e08a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Comparing Cumulative Returns\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for pair, df in result_dfs.items():\n",
    "    if 'cumulative_strategy_return' in df.columns:\n",
    "        plt.plot(df.index, df['cumulative_strategy_return'], label=f'MA {pair[0]}/{pair[1]}')\n",
    "\n",
    "plt.axhline(y=1, color='r', linestyle='--', alpha=0.3)\n",
    "plt.title(f'Comparison of Cumulative Returns for Different MA Pairs - {symbol}')\n",
    "plt.ylabel('Cumulative Return')\n",
    "plt.xlabel('Date')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(os.path.join(output_dir, f\"{symbol.lower()}_cumulative_returns_comparison.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a493c6f8-69fc-460d-a957-2714e3abe617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Drawdown Comparison\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for pair, df in result_dfs.items():\n",
    "    if 'cumulative_strategy_return' in df.columns:\n",
    "        # Calculate drawdown\n",
    "        cum_returns = df['cumulative_strategy_return']\n",
    "        running_max = cum_returns.cummax()\n",
    "        drawdown = (cum_returns / running_max) - 1\n",
    "        plt.plot(df.index, drawdown, label=f'MA {pair[0]}/{pair[1]}')\n",
    "\n",
    "plt.axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "plt.title(f'Drawdown Comparison for Different MA Pairs - {symbol}')\n",
    "plt.ylabel('Drawdown')\n",
    "plt.xlabel('Date')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(os.path.join(output_dir, f\"{symbol.lower()}_drawdown_comparison.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97806463-2f30-4df1-8364-fdb7931ce6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Return vs Volatility Scatterplot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "returns = performance_df['final_return'].values\n",
    "volatilities = performance_df['volatility'].values\n",
    "sharpe_ratios = performance_df['sharpe_ratio'].values\n",
    "labels = [f\"({short}, {long})\" for short, long in performance_df['MA Pair']]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(volatilities, returns, s=200, c=sharpe_ratios, cmap='viridis', alpha=0.7)\n",
    "\n",
    "# Add colorbar for Sharpe ratio\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Sharpe Ratio')\n",
    "\n",
    "# Add labels to each point\n",
    "for i, label in enumerate(labels):\n",
    "    plt.annotate(label, (volatilities[i], returns[i]), \n",
    "                 xytext=(7, 7), textcoords='offset points',\n",
    "                 fontsize=8, alpha=0.8)\n",
    "\n",
    "# Add reference lines\n",
    "plt.axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "plt.axvline(x=0, color='r', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.title(f'Risk-Return Profile of Different MA Pairs - {symbol}')\n",
    "plt.xlabel('Volatility (Annualized)')\n",
    "plt.ylabel('Return')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, f\"{symbol.lower()}_risk_return_profile.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9df1eb4-602a-477e-940b-467af9c28a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 4: Trading Activity Heatmap\n",
    "\n",
    "# Create a DataFrame with trading activity counts\n",
    "trading_activity = pd.DataFrame(index=pd.DatetimeIndex([]))\n",
    "\n",
    "for pair, df in result_dfs.items():\n",
    "    # Create a Series with 1 for buy signals, -1 for sell signals, 0 otherwise\n",
    "    pair_label = f\"({pair[0]}, {pair[1]})\"\n",
    "    signals = pd.Series(0, index=df.index)\n",
    "    signals[df['positions'] == 1.0] = 1  # Buy\n",
    "    signals[df['positions'] == -1.0] = -1  # Sell\n",
    "    # Only keep non-zero values\n",
    "    signals = signals[signals != 0]\n",
    "    if not signals.empty:\n",
    "        trading_activity[pair_label] = signals\n",
    "\n",
    "# If we have trading activity data\n",
    "if not trading_activity.empty:\n",
    "    # Resample to monthly frequency for better visualization\n",
    "    monthly_activity = trading_activity.resample('M').count()\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.heatmap(monthly_activity.T, cmap='YlGnBu', linewidths=0.5, \n",
    "                cbar_kws={'label': 'Number of Trades per Month'})\n",
    "    plt.title(f'Monthly Trading Activity by MA Pair - {symbol}')\n",
    "    plt.ylabel('MA Pair')\n",
    "    plt.xlabel('Month')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{symbol.lower()}_trading_activity_heatmap.png\"))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No trading activity data available for heatmap visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a989ed0-2bd6-4214-aadb-aa1f2a814cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 5: Comparative Performance Metrics\n",
    "\n",
    "# Prepare data for bar charts\n",
    "metrics = ['final_return', 'sharpe_ratio', 'max_drawdown']\n",
    "metric_labels = ['Return', 'Sharpe Ratio', 'Max Drawdown']\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i, (metric, label) in enumerate(zip(metrics, metric_labels)):\n",
    "    # Sort by the current metric\n",
    "    if metric == 'max_drawdown':\n",
    "        # For drawdown, less negative is better\n",
    "        sorted_df = performance_df.sort_values(metric, ascending=False)\n",
    "    else:\n",
    "        # For others, higher is better\n",
    "        sorted_df = performance_df.sort_values(metric, ascending=True)\n",
    "    \n",
    "    # Create bar colors based on values\n",
    "    if metric == 'max_drawdown':\n",
    "        # For drawdown, more negative values should be more red\n",
    "        colors = plt.cm.RdYlGn(np.linspace(0, 1, len(sorted_df)))\n",
    "    else:\n",
    "        # For others, higher values should be more green\n",
    "        colors = plt.cm.RdYlGn(np.linspace(0, 1, len(sorted_df)))\n",
    "    \n",
    "    # Create bar chart\n",
    "    bars = axes[i].bar(\n",
    "        [f\"({short}, {long})\" for short, long in sorted_df['MA Pair']], \n",
    "        sorted_df[metric],\n",
    "        color=colors\n",
    "    )\n",
    "    \n",
    "    # Add value labels on the bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if metric == 'sharpe_ratio':\n",
    "            label_text = f\"{height:.2f}\"\n",
    "        else:\n",
    "            label_text = f\"{height:.2%}\"\n",
    "        axes[i].text(\n",
    "            bar.get_x() + bar.get_width()/2., \n",
    "            height * (1.05 if height > 0 else 0.95),\n",
    "            label_text,\n",
    "            ha='center', va='bottom' if height > 0 else 'top',\n",
    "            fontsize=8, rotation=90\n",
    "        )\n",
    "    \n",
    "    # Configure axis\n",
    "    axes[i].set_title(label)\n",
    "    axes[i].tick_params(axis='x', rotation=90)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # For drawdown, invert y-axis to show more negative values at the bottom\n",
    "    if metric == 'max_drawdown':\n",
    "        axes[i].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, f\"{symbol.lower()}_comparative_metrics.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00617734-84c5-4d2c-acc3-db9008bad188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 6: Moving Average Crossover Points for Best Pair\n",
    "\n",
    "# Find best pair based on return\n",
    "best_pair = performance_df.iloc[0]['MA Pair']\n",
    "best_df = result_dfs[best_pair]\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot price\n",
    "plt.plot(best_df.index, best_df['price'], label='Price', color='grey', alpha=0.5)\n",
    "\n",
    "# Plot moving averages\n",
    "plt.plot(best_df.index, best_df['short_mavg'], label=f'Short MA ({best_pair[0]})', color='blue')\n",
    "plt.plot(best_df.index, best_df['long_mavg'], label=f'Long MA ({best_pair[1]})', color='green')\n",
    "\n",
    "# Highlight crossover points\n",
    "for i in range(1, len(best_df)):\n",
    "    # Check for crossover: short > long (buy)\n",
    "    if (best_df['short_mavg'].iloc[i-1] <= best_df['long_mavg'].iloc[i-1] and \n",
    "        best_df['short_mavg'].iloc[i] > best_df['long_mavg'].iloc[i]):\n",
    "        plt.scatter(best_df.index[i], best_df['short_mavg'].iloc[i], \n",
    "                   s=100, marker='^', color='green', edgecolors='black')\n",
    "    \n",
    "    # Check for crossover: short < long (sell)\n",
    "    elif (best_df['short_mavg'].iloc[i-1] >= best_df['long_mavg'].iloc[i-1] and \n",
    "          best_df['short_mavg'].iloc[i] < best_df['long_mavg'].iloc[i]):\n",
    "        plt.scatter(best_df.index[i], best_df['short_mavg'].iloc[i], \n",
    "                   s=100, marker='v', color='red', edgecolors='black')\n",
    "\n",
    "plt.title(f'Moving Average Crossovers for Best Pair MA {best_pair[0]}/{best_pair[1]} - {symbol}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, f\"{symbol.lower()}_best_pair_crossovers.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91961734-e9a5-4d66-96fd-7e8a5f4fda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary of our findings\n",
    "summary = f\"\"\"# Momentum Trading Strategy Analysis Summary\n",
    "\n",
    "## Stock: {symbol}\n",
    "\n",
    "### Best Performing Strategy\n",
    "- **MA Pair**: ({best_pair[0]}, {best_pair[1]})\n",
    "- **Return**: {performance_df.iloc[0]['final_return']:.2%}\n",
    "- **Sharpe Ratio**: {performance_df.iloc[0]['sharpe_ratio']:.2f}\n",
    "- **Max Drawdown**: {performance_df.iloc[0]['max_drawdown']:.2%}\n",
    "- **Number of Trades**: {performance_df.iloc[0]['buy_signals'] + performance_df.iloc[0]['sell_signals']}\n",
    "\n",
    "### Key Insights\n",
    "- The best performing MA pair generated a return of {performance_df.iloc[0]['final_return']:.2%} over the analysis period.\n",
    "- Shorter MA pairs ({ma_pairs[0][0]}, {ma_pairs[0][1]}) tend to generate more trading signals compared to longer MA pairs ({ma_pairs[-1][0]}, {ma_pairs[-1][1]}).\n",
    "- The tradeoff between return and volatility varies across different MA pairs, with some providing better risk-adjusted returns than others.\n",
    "- Maximum drawdown ranges from {performance_df['max_drawdown'].min():.2%} to {performance_df['max_drawdown'].max():.2%}, highlighting the importance of risk management.\n",
    "\n",
    "### Recommendations\n",
    "- Consider the ({best_pair[0]}, {best_pair[1]}) MA pair for momentum trading with {symbol} based on historical performance.\n",
    "- Take into account transaction costs and slippage, which could significantly impact actual returns, especially for strategies with higher trading frequency.\n",
    "- Combine MA crossover signals with other technical indicators to filter out false signals and improve performance.\n",
    "- Regularly reassess the optimal MA pairs as market conditions change over time.\n",
    "\"\"\"\n",
    "\n",
    "# Save summary\n",
    "with open(os.path.join(output_dir, \"analysis_summary.md\"), \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"Analysis summary saved to\", os.path.join(output_dir, \"analysis_summary.md\"))\n",
    "print(\"\\nSummary Preview:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0dc790-717d-4d72-9032-4df7588d30d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook has analyzed and visualized momentum trading strategies using different moving average pairs.\n",
    "# We've compared their performance, identified the best parameters, and gained insights into the risk-return tradeoffs.\n",
    "# This analysis can help traders make more informed decisions about which moving average parameters to use for momentum trading.\n",
    "print(\"Analysis complete! All visualizations and reports have been saved to the output directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python autogen",
   "language": "python",
   "name": "autogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
